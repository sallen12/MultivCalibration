\documentclass[article,shortnames,nojss]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% packages
\usepackage{thumbpdf,lmodern}
\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{booktabs,setspace,longtable}
\usepackage[T1]{fontenc}

%% custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\ind}{\mathbf{1}}
\newcommand{\dd}{\hspace{0.1cm} \mathrm{d}}

%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{main}
%\VignetteDepends{MultivCalibration,ggplot2,}
%\VignetteKeywords{comparative evaluation, ensemble forecasts, out-of-sample evaluation, predictive distributions, proper scoring rules, score calculation, R}
%\VignettePackage{MultivCalibration}
%\VignetteEncoding{UTF-8}

%\usepackage{Sweave}
<<preliminaries, echo=FALSE, message=FALSE>>=
# Using knitr for manuscript
library(knitr)
opts_chunk$set(engine = 'R', tidy = FALSE, message = FALSE, warning = FALSE)
#render_sweave()

# JSS code formatting
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)

# Formatting
options(scipen = 1, digits = 3)
Sys.setenv(LANG = 'en')

# RNG initialization
set.seed(801)

# Required packages
library(MultivCalibration)
library(ggplot2)
library(MASS)
library(geoR)
library(gridExtra)
@


\author{Sam Allen\\University of Bern\\Oeschger Centre for Climate Change Research}
\Plainauthor{Sam Allen}

\title{\pkg{MultivCalibration}: Assessing the calibration of multivariate probabilistic forecasts in \proglang{R}}
\Plaintitle{MultivCalibration: Assessing the calibration of multivariate probabilistic forecasts in R}
\Shorttitle{MultivCalibration}

\Abstract{
When predicting future events, it is common to issue forecasts that are probabilistic. For probabilistic forecasts to be useful, they must be calibrated, in the sense that they align statistically with the corresponding outcomes. \cite{AllenEtAl2023} introduce simple and interpretable checks for multivariate calibration that facilitate a more comprehensive understanding of how multivariate forecasts perform. This vignette reproduces the results in this paper, and demonstrates how the accompanying \proglang{R} package \pkg{MultivCalibration} allows these checks for multivariate calibration to be implemented in practice.
}

\Keywords{forecast evaluation, probabilistic forecasting, calibration, multivariate forecasting, \proglang{R}}
\Plainkeywords{forecast evaluation, probabilistic forecasting, calibration, multivariate forecasting, R}

\Address{
  Sam Allen\\
  University of Bern\\
  Institute of Mathematical Statistics and Actuarial Science\\
  Alpeneggstrasse 22\\
  3012 Bern, Switzerland\\
  E-Mail: \email{sam.allen@unibe.ch}\\
  \emph{and}\\
  Oeschger Centre for Climate Change Research\\
}


\begin{document}

\maketitle

\section{Introduction}\label{sec:intro}

Suppose we issue an ensemble forecast $\bX = (X_{1}, \dots, X_{M})$ for a real-valued quantity $Y$. The forecast is said to be probabilistically calibrated if the ensemble members and the outcome are exchangeable. Calibration is a fundamental property that probabilistic forecasts must satisfy to be considered trustworthy. To assess the probabilistic calibration of a forecast, we can calculate the rank of the outcome among the ensemble members,
\[
\mathrm{rank}(Y; \bX) = 1 + \sum_{i=1}^{M} \ind\{ X_{i} < Y \},
\]
and check whether this rank is uniformly distributed on the set $\{1, \dots, M + 1\}$ of possible ranks. Here, $\ind\{ \cdot \}$ is the indicator function, which is equal to one if the statement inside the brackets is true, and zero otherwise. In practice, we observe several realisations of $Y$ and $\bX$, and can calculate the rank for each forecast-observation pair. It is then common to display the observed ranks in a histogram. The ensemble forecast is probabilistically calibrated if this so-called rank histogram is flat. Otherwise, the shape of the histogram can be used to identify systematic errors in the forecasts: a $\cup$-shaped histogram suggests the observations are frequently either above or below all ensemble members, implying the forecasts are under-dispersed; a $\cap$-shaped histogram implies that the forecasts are over-dispersed; and a triangular histogram suggests that the forecasts tend to either over- or under-predict the outcome, indicative of a systematic forecast bias.

Due to the information they provide about forecast performance, rank histograms are well-established when evaluating ensemble forecasts. Multivariate adaptations have also been proposed to assess the calibration of multivariate ensemble forecasts, where we are interested in predicting several variables, time points, or locations simultaneously \citep[e.g.][]{GneitingEtAl2008,ThorarinsdottirEtAl2016}. Multivariate rank histograms introduce a so-called \emph{pre-rank function} that transforms the ensemble members and observations to univariate values. A univariate rank histogram can then be constructed by calculating the ranks of the transformed observations among the transformed ensemble members. Proposed approaches differ in the choice of transformation. \cite{AllenEtAl2023} argue that any function $\rho : \R^{d} \to \R$ can be used as a pre-rank function (where $d$ is the dimension of the multivariate forecasts and observations), and by choosing $\rho$ to measure a particular univariate summary statistic of the multivariate vectors, the resulting histograms will be easy to interpret and provide useful information regarding the systematic errors that occur in the forecasts.

While we discuss calibration here in the context of forecast evaluation, the methods are also applicable when validating (multivariate) probabilistic models. In this case, the output of the model can be interpreted as a probabilistic forecast for the target variable, and we can then check the model fit using the methods discussed herein.

In this vignette, we document the \pkg{MultivCalibration} \proglang{R} package, which allows multivariate rank histograms to be applied in practice. The following section introduces multivariate probabilistic calibration. Section \ref{sec:examples} then demonstrates how multivariate calibration can be assessed using \pkg{MultivCalibration}, before the package is used to reproduce the results in \cite{AllenEtAl2023}. A simulation study is presented in Section \ref{sec:simulation}, and these multivariate rank histograms are then used to evaluate probabilistic forecasts of gridded wind speed fields over Europe. A brief discussion of possible extensions is presented in Section \ref{sec:discussion}.


\section{Multivariate calibration}\label{sec:calibration}

Suppose that our ensemble members and observations are now $d$-dimensional multivariate vectors, $\bY, \bX_{1}, \dots, \bX_{M} \in \R^{d}$ for $d > 1$. While univariate probabilistic calibration can be assessed using the rank of the observation among the ensemble members, the notion of a rank is not well-defined in higher dimensions. Instead, it is common to introduce a pre-rank function
\[
\rho: \R^{d}\times \underbrace{\R^d \times \dots\times \R^d}_{\text{$M$ times}} \to \R
\]
that transforms the observation and the $M$ ensemble members to univariate values. A multivariate forecast is said to be probabilistically calibrated with respect to a pre-rank function $\rho$ if the rank of $\rho(\bY)$ among $\rho(\bX_{1}), \dots, \rho(\bX_{M})$ is uniformly distributed on the set $\{1, \dots, M + 1\}$ of possible ranks. This can be assessed by calculating the rank of several realisations of $\rho(\bY)$ among the corresponding transformed ensemble members, and plotting these ranks in a histogram. This histogram of the ranks of the transformed observations is typically called a multivariate rank histogram.

\cite{GneitingEtAl2008} demonstrate that any pre-rank function can be chosen that is invariant to permutations of the final $M$ arguments. \cite{AllenEtAl2023} remark that any function that does not depend on the final $M$ elements is trivially invariant to permutations of them, and is thus a valid pre-rank function. These are termed \emph{simple pre-rank functions}. If multivariate forecasts are auto-calibrated \citep[see][for details]{Tsyplakov2013,GneitingResin2022} then they are also probabilistically calibrated with respect to any simple pre-rank function. These simple pre-rank functions essentially choose a univariate summary statistic that quantifies some relevant characteristic of the multivariate observations, and then assess to what extent the forecasts are probabilistically calibrated when predicting this summary statistic.


\subsection{Pre-rank functions}

The choice of pre-rank function will determine how to interpret the resulting histogram. Any pre-rank function can be chosen depending on what information is of interest to the forecast users. If we are interested in predicting extreme events, we can choose a pre-rank function that quantifies the extremity of the multivariate forecast; if we are interested in the dependence between different dimensions, we can introduce a pre-rank function that quantifies this dependence. These can readily be employed in the framework above, allowing us to assess the calibration of predictions for these univariate quantities. Of course, information is lost when converting the multivariate forecasts and observations to univariate values. It is therefore generally recommended that several pre-rank functions are employed.

Different pre-rank functions have been proposed in the literature. \cite{SmithHansen2004} and \cite{Wilks2004} proposed using the inverse length of the minimum spanning tree of the set $\bX_{1}, \dots, \bX_{M}$ as a pre-rank function for $\bY$. The pre-rank of $\bX_{1}$ is the inverse length of the minimum spanning tree of the set $\bY, \bX_{2}, \dots, \bX_{M}$, with the ensemble member of interest replaced by the observation, and similarly for the other ensemble members. This is also the case for the pre-rank functions introduced below.

\cite{GneitingEtAl2008} introduced the \emph{multivariate rank} as a pre-rank function,
\[
  \rho_{mv}(\bY, \bX_{1}, \dots, \bX_{M}) = 1 + \sum_{m=1}^{M} \ind \{ \bX_{m} \preceq \bY \},
\]
where $\bX_{m} \preceq \bY$ signifies that $X_{m,j} \leq Y_{j}$ for all $j = 1, \dots, d$ with $\bX_{m} = (X_{m,1}, \dots, X_{m,d}) \in \R^{d}$ for $m = 1, \dots, M$.

\cite{ThorarinsdottirEtAl2016} proposed the \emph{average rank} along each dimension,
\[
  \rho_{av}(\bY, \bX_{1}, \dots, \bX_{M}) = \frac{1}{d} \sum_{j=1}^{d} \mathrm{rank}(Y_{j}; X_{1, j}, \dots, X_{M, j}),
\]
and the \emph{band-depth rank},
\[
  \rho_{bd}(\bY, \bX_{1}, \dots, \bX_{M}) = \frac{1}{d} \sum_{j=1}^{d} \left[ M + 1 - \mathrm{rank}(Y_{j}; X_{1, j}, \dots, X_{M, j}) \right] \left[ \mathrm{rank}(Y_{j}; X_{1, j}, \dots, X_{M, j}) - 1 \right].
\]
This representation of the band-depth rank pre-rank function assumes that there are no ties between $Y_{j}, X_{1,j}, \dots, X_{M,j}$ for $j = 1, \dots, d$, though a more general formula exists for when this is not the case.

\cite{KnuppelEtAl2022} suggested using multivariate proper scoring rules as pre-rank functions, such as the energy score,
\[
  \rho_{es}(\bY, \bX_{1}, \dots, \bX_{M}) = \frac{1}{M} \sum_{m=1}^{M} \| \bX_{m} - \bY \| - \frac{1}{2 M^{2}} \sum_{m=1}^{M} \sum_{k=1}^{M} \| \bX_{m} - \bX_{k} \|,
\]
where $\| \cdot \|$ denotes the Euclidean distance in $\R^{d}$.

\cite{ScheuererHamill2018} propose using the fraction of threshold exceedances,
\[
  \rho_{FTE}(\bY; t) = \frac{1}{d} \sum_{j=1}^{d} \ind \{ Y_{j} > t \}
\]
for some threshold $t \in \R$. In contrast to the pre-rank functions listed above, the fraction of threshold exceedances does not depend on all ensemble members, and is therefore a simple pre-rank function. In this case, we omit the ensemble members from the function arguments.

\cite{AllenEtAl2023} extend this to introduce several simple pre-rank functions. For example, the mean of the multivariate vectors could be used as a measure of the average behaviour across all dimensions,
\[
  \rho_{loc}(\bY) = \bar{Y} = \frac{1}{d} \sum_{j=1}^{d} Y_{j}.
\]
Similarly, the spread of the multivariate vector can be quantified using the sample variance,
\[
  \rho_{sc}(\bY) = s_{\bY}^{2} = \frac{1}{d} \sum_{j=1}^{d} \left( Y_{j} - \bar{Y} \right) ^{2},
\]
while the variogram quantifies the dependence between different dimensions,
\[
  \rho_{dep}(\bY; h) = -\frac{\gamma_{\bY}(h)}{s_{\bY}^{2}},
\]
for some lag $h \in \N$, where
\[
  \gamma_{\bY}(h) = \frac{1}{2 (d - h)} \sum_{j = 1}^{d - h} | Y_{j} - Y_{j + h} | ^{2}
\]
is an empirical variogram at lag $h$. The negative sign ensures that a larger value of $\rho_{dep}$ indicates a larger dependence, in keeping with $\rho_{loc}$ and $\rho_{sc}$ above. This simplifies the interpretation of the resulting multivariate rank histograms.

Further details regarding these pre-rank functions can be found in \cite{AllenEtAl2023}, where additional pre-rank functions are introduced when evaluating probabilistic spatial field forecasts.

\subsection{Pre-rank functions for gridded objects}

A particular example of a multivariate observation is a gridded object, such as a spatial field. In this case, the ensemble members and observations are matrices, rather than vectors, i.e. $\bY, \bX_{1}, \dots, \bX_{M} \in \R^{p \times q}$. These matrices can be unravelled to obtain vectors of length $d = p \times q$, but they additionally have some spatial structure that should be considered during evaluation.

The calibration of these gridded forecasts can similarly be assessed by introducing a pre-rank function
\[
\rho: \R^{p \times q} \times \underbrace{\R^{p \times q} \times \dots \times \R^{p \times q}}_{\text{$M$ times}} \to \R
\]
that converts the matrices to univariate values.

While the pre-rank functions listed above can be applied to unravelled matrices, additional pre-rank functions can also be designed that incorporate the spatial structure. For example, the variogram pre-rank function can be extended to use spatial lags $\mathbf{h} \in \{0, \dots, p - 1\} \times \{0, \dots, q - 1\}$. Let $\mathcal{I} = \{1, \dots, p\} \times \{1, \dots, q \}$ represent a set of grid points, and define the empirical variogram of a field $\bY \in \R^{p \times q}$ at multivariate lag $\mathbf{h}$ as
\[
  \gamma_{\bY}(\mathbf{h}) = \frac{1}{2|\mathcal{I}(\mathbf{h})|} \sum_{\mathbf{j} \in \mathcal{I}(\mathbf{h})} |Y_{\mathbf{j}} - Y_{\mathbf{j}+\mathbf{h}}|^{2},
\]
where $\mathcal{I}(\mathbf{h}) = \{\mathbf{j} \in \mathcal{I} : \mathbf{j} + \mathbf{h} \in \mathcal{I} \}$, meaning the sum is over all grid points that are separated by the multivariate vector $\mathbf{h}$. This can be employed within the definition of $\rho_{dep}(\bY; h)$ to construct a gridded variogram pre-rank function.

This spatial variogram can also be used to generate a pre-rank function that quantifies the isotropy of the variogram. A variogram is said to be isotropic if it depends only on the distance between elements of the multivariate vector, and not on the direction between them. By introducing a pre-rank function that measures the isotropy of an empirical variogram, we can assess to what extent the multivariate ensemble forecasts reproduce the degree of (an)isotropy present in the observed outcomes.

One example of such a pre-rank function is
\[
\rho_{iso}(\bY; h) = - \left\{ \left[ \frac{\gamma_{\bY}((h, 0)) - \gamma_{\bY}((0, h))}{\gamma_{\bY}((h, 0)) + \gamma_{\bY}((0, h))}  \right]^{2} + \left[ \frac{\gamma_{\bY}((h, h)) - \gamma_{\bY}((-h, h))}{\gamma_{\bY}((h, h)) + \gamma_{\bY}((-h, h))}  \right]^{2} \right\}.
\]
This pre-rank function quantifies the squared distance between the variogram in the horizontal direction $\mathbf{h} = (h, 0)$ and the vertical direction $\mathbf{h} = (0, h)$, plus the squared distance between the variogram in the two diagonal directions $\mathbf{h} = (h, h)$ and $\mathbf{h} = (-h, h)$. Alternative pairs of lags could also be employed.





\section{Examples}\label{sec:examples}

The \pkg{MultivCalibration} package has the functionality to compute the pre-rank functions listed above when evaluating multivariate forecasts in \proglang{R}. Pre-ranks can be obtained using the \code{get_prerank()} function
\begin{Code}
get_prerank(y, x, prerank, return_rank = TRUE, ...)
\end{Code}
which takes as inputs an observation vector \code{y} of length $d$, and a matrix of ensemble members \code{x} with $d$ rows and $M$ columns; as above $d$ is the dimension of the multivariate objects and $M$ is the number of ensemble members. While \code{get_prerank()} therefore calculates the pre-rank corresponding to one multivariate forecast and observation, the \code{apply()} functions or \code{for} loops can be used to sequentially apply \code{get_prerank()} to multiple forecasts.

The argument \code{prerank} specifies which pre-rank function should be applied to the multivariate forecasts and ensemble members. This can either be a string corresponding to one of several in-built options, or it can be a user-specified function. The in-built pre-rank functions currently available are the multivariate rank (\code{prerank = "multivariate_rank"}), the average rank (\code{prerank = "average_rank"}), the band-depth rank (\code{prerank = "band_depth"}), the mean (\code{prerank = "mean"}), the variance (\code{prerank = "variance"}), the energy score (\code{prerank = "energy_score"}), the fraction of threshold exceedances (\code{prerank = "fte_rank"}), and the variogram (\code{prerank = "variogram"}).

The argument \code{return_rank} is a logical that specifies whether the rank of the (pre-rank transformed) observation should be returned, rather than the vector of pre-ranks; the default is to return the rank, otherwise a named vector is returned containing the pre-ranks corresponding to the observation and each ensemble member.

For example, to calculate the average rank pre-rank for an observation vector and ensemble forecast, \code{get_prerank()} could be used as follows
<<get_prerank_example>>=
d <- 5
M <- 7

# generate data from a standard multivariate normal distribution
y <- as.vector(mvrnorm(1, rep(0, d), diag(d)))
x <- t(mvrnorm(M, rep(0, d), diag(d)))

# return pre-ranks
get_prerank(y, x, prerank = "average_rank", return_rank = FALSE)
# return rank of the observation pre-rank
get_prerank(y, x, prerank = "average_rank")
@

If \code{prerank} is a function, it should convert a vector of dimension $d$ to a single numeric value. Checks are in place to ensure this is satisfied. The prerank function could also take additional inputs, in which case these inputs should be included as variable arguments in \code{get_prerank()}.

For example, while the mean and variance of the multivariate vector are provided as in-built pre-rank functions, we may also want to assess the skewness of the forecasts and observations. To do so, we can define a custom pre-rank function to measure the skewness, and pass this as an input to \code{get_prerank()}.
<<get_prerank_custom_example>>=
prerank <- function(z) mean((z - mean(z))^3)
get_prerank(y, x, prerank = prerank, return_rank = FALSE)
@

This can be generalised to the $k$-th central moment of the vector, in which case the pre-rank function depends on an additional parameter $k$. This can be included in \code{get_prerank()} as an additional argument.
<<get_prerank_custom_example_varg>>=
prerank <- function(z, k) mean((z - mean(z))^k)
get_prerank(y, x, prerank = prerank, return_rank = FALSE, k = 3)
@


While \code{get_prerank()} assumes that \code{y} is a vector, pre-ranks are also available when the observations and ensemble members are matrices. The \pkg{MultivCalibration} additionally exports a function \code{get_prerank_gr()} that calculates pre-ranks corresponding to gridded objects.
\begin{Code}
get_prerank_gr(y, x, prerank, return_rank = TRUE, ...)
\end{Code}
The input \code{y} is a numeric matrix with $p$ rows and $q$ columns, while the ensemble forecast \code{x} is an array of dimension $(p, q, M)$.

The \code{prerank} argument can again be either a string corresponding to a list of in-built options for the pre-rank function, or a user-specified function. In addition to the pre-rank functions available for \code{get_prerank()}, the isotropy pre-rank function is also available (\code{prerank = "isotropy"}).




\section{Simulation study}\label{sec:simulation}

\subsection{Multivariate Gaussian}

Suppose observations are drawn from a multivariate normal distribution with mean vector $\mathbf{\mu} = \mathbf{0}$ and covariance matrix $\Sigma$ for which
\begin{equation*}
    \Sigma_{i, j} = \sigma^{2} \hspace{0.05cm} \exp\left( - \frac{|i - j|}{\tau} \right), \quad i, j = 1, \dots, d.
\end{equation*}
The parameter $\sigma^{2} > 0$ controls the variance of the observations along each dimension, while $\tau > 0$ determines how quickly the correlation decays as the distance between the dimensions increases. In this sense, there is assumed to be an ordering of the variables, as is typically the case in a time series or spatial setting. We set $d = 10$, $\sigma^{2} = 1$, and $\tau = 1$. Analogous conclusions are also drawn from other configurations.

For each observation, $M = 20$ ensemble members are drawn at random from a mis-specified multivariate normal distribution. We consider six possible mis-specifications, corresponding to under- and over-estimation of the mean vector $\mathbf{\mu}$, scale parameter $\sigma^{2}$, and correlation parameter $\tau$.

<<sim_study_mvn_setup>>=
d <- 10       # dimensions
n <- 100      # number of iterations (10000 is used in Allen et al. (2023))
M <- 20       # number of samples from the forecast distribution

sig2 <- 1     # variance parameter
tau <- 1      # correlation parameter
@


The observations are drawn from a multivariate normal distribution with the following mean vector (\code{mu_y}) and covariance matrix (\code{Sig_y})

<<sim_study_mvn_obs>>=
mu_y <- rep(0, d)
Sig_y <- outer(1:d, 1:d, function(i, j) sig2*exp(-abs(i - j)/tau))
y <- mvrnorm(n, mu = mu_y, Sigma = Sig_y)
@

Firstly, consider errors in the mean. Suppose that the forecasts are obtained from a multivariate normal distribution with the correct covariance matrix, but with mean vector $\mu = (-0.5, \dots, -0.5)$ (of length $d$).

<<sim_study_mvn_ens_1>>=
mu_x <- rep(-0.5, d)
x <- replicate(M, mvrnorm(n, mu = mu_x, Sigma = Sig_y))
@

The resulting \code{x} is an array of dimension $(n, d, M)$. We can use the \code{get_prerank()} function to extract the multivariate rank for different pre-rank functions. For example, consider the average rank pre-rank function applied to the first forecast-observation pair

<<sim_study_mvn_ex_1>>=
get_prerank(y[1, ], x[1, , ], prerank = "average_rank")
@

We can use \code{sapply()} to loop over all $n$ observations. We repeat this for all pre-rank functions, and store the result in a data frame.

<<sim_study_mvn_rankdf_1>>=
# specify weight matrix for variogram pre-rank function
w_mat <- matrix(as.numeric(abs(outer(1:d, 1:d, FUN = "-")) <= 1), nrow = d)

rank_df <- sapply(1:n, function(i) {
  mvr <- get_prerank(y[i, ], x[i, , ], prerank = "multivariate_rank")
  avr <- get_prerank(y[i, ], x[i, , ], prerank = "average_rank")
  bdr <- get_prerank(y[i, ], x[i, , ], prerank = "band_depth")
  esr <- get_prerank(y[i, ], x[i, , ], prerank = "energy_score")
  loc <- get_prerank(y[i, ], x[i, , ], prerank = "mean")
  var <- get_prerank(y[i, ], x[i, , ], prerank = "variance")
  vgr <- get_prerank(y[i, ], x[i, , ], w = w_mat, prerank = "variogram")
  ranks <- c(mvr, avr, bdr, esr, loc, var, vgr)
  names(ranks) <- c("mvr", "avr", "bdr", "esr", "loc", "var", "vgr")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

# display the observation pre-ranks for the first 10 forecast cases
head(rank_df, 10)
@

To display the multivariate rank histograms corresponding to each pre-rank function, we first define a function \code{pit_hist}. This function is also available from the \pkg{WeightedForecastVerification} package on GitHub, which can be installed using \pkg{devtools}

\begin{Code}
devtools::install_github("sallen12/WeightedForecastVerification")
\end{Code}

<<pit_hist_function, echo=FALSE>>=
pit_hist <- function(z, bins = NULL, ranks = TRUE, title = NULL, ymax = NULL,
                     ylab = "Rel. Freq.", xlab = "Rank",
                     yticks = TRUE, xticks = TRUE,
                     linecol = "red", linetype = "dashed") {

  if (is.null(bins)) {
    if(!ranks) {
      bins <- 10
    }else {
      bins <- max(z, na.rm = T)
    }
  }

  if (!ranks) z <- floor(z*bins) + 1; z[z > bins] <- bins

  rank_freq <- sapply(1:bins, function(i) mean(z == i, na.rm = T))
  if (is.null(ymax)) ymax <- 1.5*max(rank_freq)

  alpha <- 1
  if (is.null(linecol) || is.null(linetype)) {linecol <- "red"; linetype <- "dashed"; alpha <- 0}

  df <- data.frame(freq = rank_freq, rank = as.factor(1:bins))
  out_plot <- ggplot2::ggplot(df, ggplot2::aes(x = rank, y = freq)) +
    ggplot2::geom_bar(stat = "identity") +
    ggplot2::geom_hline(ggplot2::aes(yintercept = 1/bins), col = linecol, alpha = alpha, lty = linetype) +
    ggplot2::scale_x_discrete(name = xlab) +
    ggplot2::scale_y_continuous(name = ylab, limits = c(0, ymax), expand = c(0, 0)) +
    ggplot2::theme_bw() +
    ggplot2::theme(legend.title = ggplot2::element_blank(), panel.grid = ggplot2::element_blank()) +
    ggplot2::ggtitle(title)
  if (!yticks) out_plot <- out_plot + ggplot2::theme(axis.ticks.y = ggplot2::element_blank(),
                                                     axis.text.y = ggplot2::element_blank())
  if (!xticks) out_plot <- out_plot + ggplot2::theme(axis.ticks.x = ggplot2::element_blank(),
                                                     axis.text.x = ggplot2::element_blank())
  return(out_plot)
}
@

Consider the average rank as an example again. The multivariate rank histogram corresponding to this pre-rank function is displayed in Figure~\ref{fig:mvrhist_ex}.

<<plot_histograms_1code, fig.show='hide'>>=
pit_hist(rank_df$avr, ylab = "Average rank", xticks = FALSE)
@

\begin{figure}
<<plot_histograms_1plot, echo=FALSE, dev='pdf', fig.width=2.5, fig.height=2.3, fig.align='center'>>=
pit_hist(rank_df$avr, ylab = "Average rank", xticks = FALSE)
@
\caption{Multivariate rank histogram for the average rank pre-rank function in the multivariate normal simulation study.}
\label{fig:mvrhist_ex}
\end{figure}

This can be repeated for all pre-rank functions, and for different types of errors. For example, when there is a positive bias in the forecasts, rather than a negative one: \code{mu_x = rep(0.5, d)}.

<<plot_histograms_1_gE, echo=FALSE, fig.show='hide'>>=
pr_names <- c("Multivariate", "Average rank", "Band-depth",
              "Energy score", "Location", "Scale", "Dependence")
plot_list <- lapply(seq_along(pr_names), function(i) {
  pit_hist(rank_df[[i]], ylab = pr_names[i], ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
})
plot_list[["ncol"]] <- 1
plot_mean1 <- do.call(grid.arrange, plot_list)
@

<<sim_study_mvn_rankdf_2, echo=FALSE, fig.show='hide'>>=
mu_x <- rep(0.5, d)
x <- replicate(M, mvrnorm(n, mu = mu_x, Sigma = Sig_y))

rank_df <- sapply(1:n, function(i) {
  mvr <- get_prerank(y[i, ], x[i, , ], prerank = "multivariate_rank")
  avr <- get_prerank(y[i, ], x[i, , ], prerank = "average_rank")
  bdr <- get_prerank(y[i, ], x[i, , ], prerank = "band_depth")
  esr <- get_prerank(y[i, ], x[i, , ], prerank = "energy_score")
  loc <- get_prerank(y[i, ], x[i, , ], prerank = "mean")
  var <- get_prerank(y[i, ], x[i, , ], prerank = "variance")
  vgr <- get_prerank(y[i, ], x[i, , ], w = w_mat, prerank = "variogram")
  ranks <- c(mvr, avr, bdr, esr, loc, var, vgr)
  names(ranks) <- c("mvr", "avr", "bdr", "esr", "loc", "var", "vgr")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(rank_df, pit_hist, ylab = "", ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
plot_list[["ncol"]] <- 1
plot_mean2 <- do.call(grid.arrange, plot_list)
@

We can additionally see the behaviour of the multivariate rank histograms when we change the scale of the multivariate normal distribution.

<<sim_study_mvn_ens_3>>=
sig2_x <- 0.85
Sig_x <- Sig_y*sig2_x
x <- replicate(M, mvrnorm(n, mu = mu_y, Sigma = Sig_x))
@

<<sim_study_mvn_rankdf_3, echo=FALSE, fig.show='hide'>>=
rank_df <- sapply(1:n, function(i) {
  mvr <- get_prerank(y[i, ], x[i, , ], prerank = "multivariate_rank")
  avr <- get_prerank(y[i, ], x[i, , ], prerank = "average_rank")
  bdr <- get_prerank(y[i, ], x[i, , ], prerank = "band_depth")
  esr <- get_prerank(y[i, ], x[i, , ], prerank = "energy_score")
  loc <- get_prerank(y[i, ], x[i, , ], prerank = "mean")
  var <- get_prerank(y[i, ], x[i, , ], prerank = "variance")
  vgr <- get_prerank(y[i, ], x[i, , ], w = w_mat, prerank = "variogram")
  ranks <- c(mvr, avr, bdr, esr, loc, var, vgr)
  names(ranks) <- c("mvr", "avr", "bdr", "esr", "loc", "var", "vgr")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(rank_df, pit_hist, ylab = "", ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
plot_list[["ncol"]] <- 1
plot_sc1 <- do.call(grid.arrange, plot_list)
@

This can similarly be repeated using \code{sig2_x = 1.25} to analyse over-dispersion in the multivariate forecast distributions.

<<sim_study_mvn_rankdf_4, echo=FALSE, fig.show='hide'>>=
sig2_x <- 1.35
Sig_x <- Sig_y*sig2_x
x <- replicate(M, mvrnorm(n, mu = mu_y, Sigma = Sig_x))

rank_df <- sapply(1:n, function(i) {
  mvr <- get_prerank(y[i, ], x[i, , ], prerank = "multivariate_rank")
  avr <- get_prerank(y[i, ], x[i, , ], prerank = "average_rank")
  bdr <- get_prerank(y[i, ], x[i, , ], prerank = "band_depth")
  esr <- get_prerank(y[i, ], x[i, , ], prerank = "energy_score")
  loc <- get_prerank(y[i, ], x[i, , ], prerank = "mean")
  var <- get_prerank(y[i, ], x[i, , ], prerank = "variance")
  vgr <- get_prerank(y[i, ], x[i, , ], w = w_mat, prerank = "variogram")
  ranks <- c(mvr, avr, bdr, esr, loc, var, vgr)
  names(ranks) <- c("mvr", "avr", "bdr", "esr", "loc", "var", "vgr")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(rank_df, pit_hist, ylab = "", ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
plot_list[["ncol"]] <- 1
plot_sc2 <- do.call(grid.arrange, plot_list)
@

We can also make changes to the dependence structure. For example, consider $\tau = 0.5$ rather than $1$.

<<sim_study_mvn_ens_5>>=
tau_x <- 0.5
Sig_x <- outer(1:d, 1:d, function(i, j) sig2*exp(-abs(i - j)/tau_x))
x <- replicate(M, mvrnorm(n, mu = mu_y, Sigma = Sig_x))
@

<<sim_study_mvn_rankdf_5, echo=FALSE, fig.show='hide'>>=
rank_df <- sapply(1:n, function(i) {
  mvr <- get_prerank(y[i, ], x[i, , ], prerank = "multivariate_rank")
  avr <- get_prerank(y[i, ], x[i, , ], prerank = "average_rank")
  bdr <- get_prerank(y[i, ], x[i, , ], prerank = "band_depth")
  esr <- get_prerank(y[i, ], x[i, , ], prerank = "energy_score")
  loc <- get_prerank(y[i, ], x[i, , ], prerank = "mean")
  var <- get_prerank(y[i, ], x[i, , ], prerank = "variance")
  vgr <- get_prerank(y[i, ], x[i, , ], w = w_mat, prerank = "variogram")
  ranks <- c(mvr, avr, bdr, esr, loc, var, vgr)
  names(ranks) <- c("mvr", "avr", "bdr", "esr", "loc", "var", "vgr")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(rank_df, pit_hist, ylab = "", ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
plot_list[["ncol"]] <- 1
plot_corr1 <- do.call(grid.arrange, plot_list)
@

This is also repeated using $\tau = 1.5$, as an example of when the dependence is too strong.

<<sim_study_mvn_rankdf_6, echo=FALSE, fig.show='hide'>>=
tau_x <- 5
Sig_x <- outer(1:d, 1:d, function(i, j) sig2*exp(-abs(i - j)/tau_x))
x <- replicate(M, mvrnorm(n, mu = mu_y, Sigma = Sig_x))

rank_df <- sapply(1:n, function(i) {
  mvr <- get_prerank(y[i, ], x[i, , ], prerank = "multivariate_rank")
  avr <- get_prerank(y[i, ], x[i, , ], prerank = "average_rank")
  bdr <- get_prerank(y[i, ], x[i, , ], prerank = "band_depth")
  esr <- get_prerank(y[i, ], x[i, , ], prerank = "energy_score")
  loc <- get_prerank(y[i, ], x[i, , ], prerank = "mean")
  var <- get_prerank(y[i, ], x[i, , ], prerank = "variance")
  vgr <- get_prerank(y[i, ], x[i, , ], w = w_mat, prerank = "variogram")
  ranks <- c(mvr, avr, bdr, esr, loc, var, vgr)
  names(ranks) <- c("mvr", "avr", "bdr", "esr", "loc", "var", "vgr")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(rank_df, pit_hist, ylab = "", ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
plot_list[["ncol"]] <- 1
plot_corr2 <- do.call(grid.arrange, plot_list)
@

Repeating this for all pre-rank functions and all six types of misspecification, we can plot the multivariate rank histograms together.

\begin{figure}
<<plot_histograms, echo=FALSE, dev='pdf', fig.width=10.4, fig.height=10.4, fig.align='center', out.width = '\\linewidth'>>=
grid.arrange(plot_mean1, plot_mean2, plot_sc1, plot_sc2, plot_corr1, plot_corr2, ncol = 6)
@
\caption{Multivariate rank histogram for seven pre-rank functions and the six types of mis-specification in the multivariate forecast distributions.}
\label{fig:mvnhists}
\end{figure}


\subsection{Gaussian random fields}

Now consider a second simulation study in which the forecasts and observations are gridded fields rather than multivariate vectors, with $p = q = 30$. This extends the previous example to a higher dimensional setting in which there is additionally spatial structure present in the data. The observations are drawn from a zero-mean Gaussian random field with an exponential covariance function such that the covariance between two locations $\mathbf{i}$ and $\mathbf{j}$ on the grid is
\[
\sigma^{2} \hspace{0.05cm} \exp\left( - \frac{||\mathbf{i} - \mathbf{j}||}{\tau} \right), \quad \mathbf{i}, \mathbf{j} \in \{1, \dots, 30\} \times \{1, \dots, 30\}.
\]

We can use the \pkg{geoR} package to obtain realisations of a Gaussian random field with these parameters. An example field is shown in Figure \ref{fig:grf_example}.

<<sim_study_grf_obs>>=
d <- 30^2
n <- 10
M <- 20
sig2 <- 1
tau <- 1

y <- grf(d, grid = "reg", cov.pars = c(sig2, tau), nsim = n, messages = F)
@

\begin{figure}
<<plot_fields, echo=FALSE, dev='pdf', fig.width=2.5, fig.height=2.5, fig.align='center'>>=
coords <- y$coords*(sqrt(d) - 1)
y <- y$data
dim(y) <- c(sqrt(d), sqrt(d), n)

plot_grf <- function(coords, z) {
  grf_df <- data.frame(x = coords[, 1], y = coords[, 2], z)
  ggplot(grf_df) + geom_raster(aes(x = x, y = y, fill = z)) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    scale_fill_distiller(limits = c(-3, 3), palette = "RdBu") +
    theme(axis.title = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          legend.position = "none")
}

plot_grf(coords, as.vector(y[, , sample(1:n, 1)]))
@
\caption{Example realisation of a Gaussian random field.}
\label{fig:grf_example}
\end{figure}

Forecasts are then generated from mis-specified Gaussian random fields. We again consider six different types of mis-specification, corresponding to the scale, correlation, and isotropy of the random fields. For example, we can obtain ensemble members that under-estimate the scale in the observation fields using

<<sim_study_grf_ens1>>=
sig2_x <- 0.85
x <- grf(d, grid = "reg", cov.pars = c(sig2_x, tau), nsim = n*M, messages = F)
x <- x$data
dim(x) <- c(sqrt(d), sqrt(d), M, n)
@

We can use the \code{get_prerank_gr()} function to extract the multivariate rank for different pre-rank functions, and use \code{sapply()} to loop over all $n$ observations. Note that the variogram, fraction of threshold exceedances, and isotropy pre-rank functions require additional arguments corresponding to the threshold or spatial lag(s).

<<sim_study_grf_rankdf_1>>=
t <- 1
h <- rbind(c(0, 1), c(1, 0), c(1, 1), c(1, -1))

rank_df <- sapply(1:n, function(i) {
  avr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "average_rank")
  bdr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "band_depth")
  loc <- get_prerank_gr(y[, , i], x[, , , i], prerank = "mean")
  var <- get_prerank_gr(y[, , i], x[, , , i], prerank = "variance")
  vgr <- get_prerank_gr(y[, , i], x[, , , i], h = h, prerank = "variogram")
  fte <- get_prerank_gr(y[, , i], x[, , , i], t = t, prerank = "FTE")
  iso <- get_prerank_gr(y[, , i], x[, , , i], prerank = "isotropy")
  ranks <- c(avr, bdr, loc, var, vgr, fte, iso)
  names(ranks) <- c("avr", "bdr", "loc", "var", "vgr", "fte", "iso")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))
@


<<plot_histograms_grf_1, echo=FALSE, fig.show='hide'>>=
pr_names <- c("Average rank", "Band-depth", "Location", "Scale",
              "Dependence", "FTE", "Isotropy")
plot_list <- lapply(seq_along(pr_names), function(i) {
  pit_hist(rank_df[[i]], ylab = pr_names[i], ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
})
plot_list[["ncol"]] <- 1
plot_sc1 <- do.call(grid.arrange, plot_list)
@

<<sim_study_grf_rankdf_2, echo=FALSE, fig.show='hide'>>=
sig2_x <- 1.25
x <- grf(d, grid = "reg", cov.pars = c(sig2_x, tau), nsim = n*M, messages = F)$data
dim(x) <- c(sqrt(d), sqrt(d), M, n)

rank_df <- sapply(1:n, function(i) {
  avr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "average_rank")
  bdr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "band_depth")
  loc <- get_prerank_gr(y[, , i], x[, , , i], prerank = "mean")
  var <- get_prerank_gr(y[, , i], x[, , , i], prerank = "variance")
  vgr <- get_prerank_gr(y[, , i], x[, , , i], h = h, prerank = "variogram")
  fte <- get_prerank_gr(y[, , i], x[, , , i], t = t, prerank = "FTE")
  iso <- get_prerank_gr(y[, , i], x[, , , i], prerank = "isotropy")
  ranks <- c(avr, bdr, loc, var, vgr, fte, iso)
  names(ranks) <- c("avr", "bdr", "loc", "var", "vgr", "fte", "iso")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(seq_along(pr_names), function(i) {
  pit_hist(rank_df[[i]], ylab = pr_names[i], ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
})
plot_list[["ncol"]] <- 1
plot_sc2 <- do.call(grid.arrange, plot_list)
@

We can similarly calculate the pre-ranks when the ensemble forecasts over-estimate the scale of the observed fields, and when there are errors in the correlation structure,

<<sim_study_grf_rankdf_3_dat, echo=FALSE, fig.show='hide'>>=
tau_x <- 0.5
x <- grf(d, grid = "reg", cov.pars = c(sig2, tau_x), nsim = n*M, messages = F)
@

<<sim_study_grf_rankdf_3, echo=FALSE, fig.show='hide'>>=
x <- x$data
dim(x) <- c(sqrt(d), sqrt(d), M, n)

rank_df <- sapply(1:n, function(i) {
  avr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "average_rank")
  bdr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "band_depth")
  loc <- get_prerank_gr(y[, , i], x[, , , i], prerank = "mean")
  var <- get_prerank_gr(y[, , i], x[, , , i], prerank = "variance")
  vgr <- get_prerank_gr(y[, , i], x[, , , i], h = h, prerank = "variogram")
  fte <- get_prerank_gr(y[, , i], x[, , , i], t = t, prerank = "FTE")
  iso <- get_prerank_gr(y[, , i], x[, , , i], prerank = "isotropy")
  ranks <- c(avr, bdr, loc, var, vgr, fte, iso)
  names(ranks) <- c("avr", "bdr", "loc", "var", "vgr", "fte", "iso")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(seq_along(pr_names), function(i) {
  pit_hist(rank_df[[i]], ylab = pr_names[i], ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
})
plot_list[["ncol"]] <- 1
plot_corr1 <- do.call(grid.arrange, plot_list)
@

<<sim_study_grf_rankdf_4, echo=FALSE, fig.show='hide'>>=
tau_x <- 2
x <- grf(d, grid = "reg", cov.pars = c(sig2, tau_x), nsim = n*M, messages = F)$data
dim(x) <- c(sqrt(d), sqrt(d), M, n)

rank_df <- sapply(1:n, function(i) {
  avr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "average_rank")
  bdr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "band_depth")
  loc <- get_prerank_gr(y[, , i], x[, , , i], prerank = "mean")
  var <- get_prerank_gr(y[, , i], x[, , , i], prerank = "variance")
  vgr <- get_prerank_gr(y[, , i], x[, , , i], h = h, prerank = "variogram")
  fte <- get_prerank_gr(y[, , i], x[, , , i], t = t, prerank = "FTE")
  iso <- get_prerank_gr(y[, , i], x[, , , i], prerank = "isotropy")
  ranks <- c(avr, bdr, loc, var, vgr, fte, iso)
  names(ranks) <- c("avr", "bdr", "loc", "var", "vgr", "fte", "iso")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(seq_along(pr_names), function(i) {
  pit_hist(rank_df[[i]], ylab = pr_names[i], ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
})
plot_list[["ncol"]] <- 1
plot_corr2 <- do.call(grid.arrange, plot_list)
@

and the isotropy.

<<sim_study_grf_ens_5>>=
# rescale the fields vertically by a factor of 5/4
x <- grf(d, grid = "reg", cov.pars = c(sig2, tau), aniso.pars = c(0, 5/4),
         nsim = n*M, messages = F)
@

<<sim_study_grf_rankdf_5, echo=FALSE, fig.show='hide'>>=
x <- x$data
dim(x) <- c(sqrt(d), sqrt(d), M, n)

rank_df <- sapply(1:n, function(i) {
  avr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "average_rank")
  bdr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "band_depth")
  loc <- get_prerank_gr(y[, , i], x[, , , i], prerank = "mean")
  var <- get_prerank_gr(y[, , i], x[, , , i], prerank = "variance")
  vgr <- get_prerank_gr(y[, , i], x[, , , i], h = h, prerank = "variogram")
  fte <- get_prerank_gr(y[, , i], x[, , , i], t = t, prerank = "FTE")
  iso <- get_prerank_gr(y[, , i], x[, , , i], prerank = "isotropy")
  ranks <- c(avr, bdr, loc, var, vgr, fte, iso)
  names(ranks) <- c("avr", "bdr", "loc", "var", "vgr", "fte", "iso")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(seq_along(pr_names), function(i) {
  pit_hist(rank_df[[i]], ylab = pr_names[i], ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
})
plot_list[["ncol"]] <- 1
plot_iso1 <- do.call(grid.arrange, plot_list)
@

<<sim_study_grf_rankdf_6, echo=FALSE, fig.show='hide'>>=
y <- grf(d, grid = "reg", cov.pars = c(sig2, tau), aniso.pars = c(0, 5/4), nsim = n, messages = F)$data
dim(y) <- c(sqrt(d), sqrt(d), n)
x <- grf(d, grid = "reg", cov.pars = c(sig2, tau), nsim = n*M, messages = F)$data
dim(x) <- c(sqrt(d), sqrt(d), M, n)

rank_df <- sapply(1:n, function(i) {
  avr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "average_rank")
  bdr <- get_prerank_gr(y[, , i], x[, , , i], prerank = "band_depth")
  loc <- get_prerank_gr(y[, , i], x[, , , i], prerank = "mean")
  var <- get_prerank_gr(y[, , i], x[, , , i], prerank = "variance")
  vgr <- get_prerank_gr(y[, , i], x[, , , i], h = h, prerank = "variogram")
  fte <- get_prerank_gr(y[, , i], x[, , , i], t = t, prerank = "FTE")
  iso <- get_prerank_gr(y[, , i], x[, , , i], prerank = "isotropy")
  ranks <- c(avr, bdr, loc, var, vgr, fte, iso)
  names(ranks) <- c("avr", "bdr", "loc", "var", "vgr", "fte", "iso")
  return(ranks)
})
rank_df <- data.frame(t(rank_df))

plot_list <- lapply(seq_along(pr_names), function(i) {
  pit_hist(rank_df[[i]], ylab = pr_names[i], ymax = 0.4, xlab = NULL, xticks = F, yticks = F)
})
plot_list[["ncol"]] <- 1
plot_iso2 <- do.call(grid.arrange, plot_list)
@

The resulting multivariate rank histograms are displayed in Figure \ref{fig:grfhists}.

\begin{figure}
<<plot_histograms_grf, echo=FALSE, dev='pdf', fig.width=10.4, fig.height=10.4, fig.align='center', out.width = '\\linewidth'>>=
gridExtra::grid.arrange(plot_sc1, plot_sc2, plot_corr1, plot_corr2, plot_iso1, plot_iso2, ncol = 6)
@
\caption{Multivariate rank histogram for seven pre-rank functions and the six types of mis-specification in the forecast fields.}
\label{fig:grfhists}
\end{figure}


\section{Discussion}\label{sec:discussion}

This vignette discusses the \proglang{R} package \pkg{MultivCalibration}, which facilitates the assessment of multivariate probabilistic forecasts. The package consists of several pre-rank functions that can be used to construct multivariate rank histograms, allowing users to visualise the calibration of multivariate forecasts. To demonstrate the usage of the package, it is used to reproduce the results in \cite{AllenEtAl2023}.

The package contains pre-rank functions previously proposed in the literature, including the multivariate rank of \cite{GneitingEtAl2008}, the average rank and band-depth rank of \cite{ThorarinsdottirEtAl2016}, and a collection of simple pre-rank functions listed in \cite{AllenEtAl2023}. There is also the option for users to employ custom pre-rank functions that can extract user-specific information about multivariate forecast performance. Additional pre-rank functions could additionally be made available in the future, including the minimum spanning tree-based pre-rank function proposed by \cite{SmithHansen2004} and \cite{Wilks2004}.

The package is still in development, and several other extensions could also be included. The package currently contains pre-rank functions suitable for multivariate forecasts and observations, though the same framework can readily be applied when assessing the calibration of forecasts for other objects, such as networks or graphs. Pre-rank functions could therefore be introduced for forecasts in this form. Furthermore, while the package allows for user-specified pre-rank functions, these custom pre-rank functions must be simple. There is currently not the functionality to employ custom pre-rank functions that are not simple.


%% Bibliography
\bibliography{bibliography}

\end{document}
